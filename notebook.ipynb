{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from post_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado en: holy_grail/labels/DREB_all.csv\n",
      "Archivo guardado en: holy_grail/labels/OREB_all.csv\n"
     ]
    }
   ],
   "source": [
    "df = concatenate_playtype_seasons(play_type='DREB', seasons='All', save=True)\n",
    "df = concatenate_playtype_seasons(play_type='OREB', seasons='All', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo limpio guardado en: holy_grail/labels/DREB_all.csv\n",
      "Archivo limpio guardado en: holy_grail/labels/OREB_all.csv\n"
     ]
    }
   ],
   "source": [
    "clean_missing_video_data('DREB_all.csv', True)\n",
    "clean_missing_video_data('OREB_all.csv', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download frames from vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extrayendo frames: 100%|██████████| 621/621 [00:09<00:00, 67.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames guardados en frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import imageio.v3 as iio\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_frames(video_path, output_folder, fps=30, resolution=None):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    frames = iio.imread(video_path, plugin=\"pyav\", index=None)  # Cargar todos los frames\n",
    "    total_frames = len(frames[::int(30/fps)])\n",
    "    \n",
    "    for i, frame in tqdm(enumerate(frames[::int(30/fps)]), total=total_frames, desc=\"Extrayendo frames\"):\n",
    "        if resolution:\n",
    "            frame = cv2.resize(frame, resolution, interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        image_path = os.path.join(output_folder, f\"frame_{i:04d}.png\")\n",
    "        iio.imwrite(image_path, frame)\n",
    "    \n",
    "    print(f\"Frames guardados en {output_folder}\")\n",
    "\n",
    "extract_frames(\"ignore/example_video.mp4\", \"frames\", fps=30, resolution=(640, 360))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count unique players in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de jugadores distintos es: 817\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_unique_players(file_path1, file_path2):\n",
    "    df1 = pd.read_csv(file_path1)\n",
    "    df2 = pd.read_csv(file_path2)\n",
    "    combined_df = pd.concat([df1, df2])\n",
    "    unique_players = combined_df['PLAYER NAME'].nunique()\n",
    "    return unique_players\n",
    "\n",
    "# Ejemplo de uso\n",
    "file_path1 = 'holy_grail/labels/OREB_all.csv'\n",
    "file_path2 = 'holy_grail/labels/DREB_all.csv'\n",
    "print(f\"El número de jugadores distintos es: {count_unique_players(file_path1, file_path2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/arnaubarrera/Desktop/MSc Computer Vision/TFM/labeled_plays_NBA\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "directorio_actual = os.getcwd()\n",
    "print(directorio_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna 'DOWNLOADED' añadida y archivos sobrescritos exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_downloaded_column():\n",
    "    # Leer los archivos CSV\n",
    "    oreb_df = pd.read_csv(\"holy_grail/labels/OREB_all.csv\")\n",
    "    dreb_df = pd.read_csv(\"holy_grail/labels/DREB_all.csv\")\n",
    "    \n",
    "    # Añadir la columna 'DOWNLOADED' con valores False\n",
    "    oreb_df[\"DOWNLOADED\"] = False\n",
    "    dreb_df[\"DOWNLOADED\"] = False\n",
    "    \n",
    "    # Sobrescribir los archivos con la nueva columna\n",
    "    oreb_df.to_csv(\"holy_grail/labels/OREB_all.csv\", index=False)\n",
    "    dreb_df.to_csv(\"holy_grail/labels/DREB_all.csv\", index=False)\n",
    "    \n",
    "    print(\"Columna 'DOWNLOADED' añadida y archivos sobrescritos exitosamente.\")\n",
    "\n",
    "# Llamar a la función\n",
    "add_downloaded_column()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "oreb = pd.read_csv('HoopCut_net/OREB_all.csv')\n",
    "dreb = pd.read_csv('HoopCut_net/DREB_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_csv_files(file1, file2, output_file):\n",
    "    # Leer los archivos CSV\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "    \n",
    "    # Lista para almacenar las filas seleccionadas\n",
    "    selected_rows = []\n",
    "    \n",
    "    # Función para seleccionar filas aleatorias y actualizar 'DOWNLOADED'\n",
    "    def select_random_rows(df):\n",
    "        # Obtener valores únicos de la columna 'SEASON'\n",
    "        unique_seasons = df['SEASON'].unique()\n",
    "        \n",
    "        for season in unique_seasons:\n",
    "            # Filtrar filas por 'SEASON'\n",
    "            season_rows = df[df['SEASON'] == season]\n",
    "            # Seleccionar 25 filas aleatorias\n",
    "            random_rows = season_rows.sample(n=min(25, len(season_rows)), random_state=1)\n",
    "            # Establecer 'DOWNLOADED' a True\n",
    "            df.loc[random_rows.index, 'DOWNLOADED'] = True  # Actualizar directamente el DataFrame original\n",
    "            # Añadir las filas seleccionadas a la lista\n",
    "            selected_rows.append(random_rows)\n",
    "    \n",
    "    # Seleccionar filas de ambos DataFrames y actualizar 'DOWNLOADED'\n",
    "    select_random_rows(df1)\n",
    "    select_random_rows(df2)\n",
    "    \n",
    "    # Concatenar todas las filas seleccionadas en un nuevo DataFrame\n",
    "    selected_df = pd.concat(selected_rows, ignore_index=True)\n",
    "    \n",
    "    # Guardar los DataFrames actualizados en sus archivos originales\n",
    "    df1.to_csv(file1, index=False)\n",
    "    df2.to_csv(file2, index=False)\n",
    "    \n",
    "    # Guardar el nuevo DataFrame con las filas seleccionadas en un archivo CSV\n",
    "    selected_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Uso de la función\n",
    "file1 = 'HoopCut_net/DREB_all.csv'  # Cambia esto por el nombre de tu archivo\n",
    "file2 = 'HoopCut_net/OREB_all.csv'  # Cambia esto por el nombre de tu archivo\n",
    "output_file = 'HoopCut_net/labels_HoopCut.csv'  # Archivo de salida para las filas seleccionadas\n",
    "\n",
    "process_csv_files(file1, file2, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_true_values(df, column_name):\n",
    "    \"\"\"\n",
    "    Cuenta cuántos valores True hay en una columna dada de un DataFrame.\n",
    "\n",
    "    :param df: DataFrame de pandas.\n",
    "    :param column_name: Nombre de la columna donde contar los valores True.\n",
    "    :return: Número de valores True en la columna especificada.\n",
    "    \"\"\"\n",
    "    if column_name in df.columns:\n",
    "        return df[column_name].sum()  # Suma los valores True (1) en la columna\n",
    "    else:\n",
    "        raise ValueError(f\"La columna '{column_name}' no existe en el DataFrame.\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "df = pd.read_csv('HoopCut_net/DREB_all.csv')\n",
    "count_true = count_true_values(df, 'DOWNLOADED')\n",
    "print(count_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_string_occurrences(df, column_name, target_string):\n",
    "    \"\"\"\n",
    "    Cuenta cuántas veces aparece una cadena específica en una columna dada de un DataFrame.\n",
    "\n",
    "    :param df: DataFrame de pandas.\n",
    "    :param column_name: Nombre de la columna donde contar las ocurrencias.\n",
    "    :param target_string: Cadena a contar en la columna.\n",
    "    :return: Número de ocurrencias de la cadena en la columna especificada.\n",
    "    \"\"\"\n",
    "    if column_name in df.columns:\n",
    "        return (df[column_name] == target_string).sum()  # Suma las ocurrencias de la cadena\n",
    "    else:\n",
    "        raise ValueError(f\"La columna '{column_name}' no existe en el DataFrame.\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "df = pd.read_csv(output_file)\n",
    "count_occurrences = count_string_occurrences(df, 'REBOUND TYPE', 'DREB')\n",
    "print(count_occurrences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_play_id_column(file_path, output_file):\n",
    "    \"\"\"\n",
    "    Lee un archivo CSV, añade una columna 'PLAY ID' y desplaza las demás columnas hacia la derecha.\n",
    "\n",
    "    :param file_path: Ruta del archivo CSV original.\n",
    "    :param output_file: Ruta del archivo CSV de salida con la nueva columna.\n",
    "    \"\"\"\n",
    "    # Leer el archivo CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Crear la nueva columna 'PLAY ID' con el formato deseado\n",
    "    df.insert(0, 'PLAY ID', [f'hoop_cut_{i+1}' for i in range(len(df))])\n",
    "\n",
    "    # Guardar el DataFrame actualizado en un nuevo archivo CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "# Ejemplo de uso\n",
    "input_file = output_file  # Cambia esto por el nombre de tu archivo\n",
    "output_file = output_file  # Archivo de salida\n",
    "add_play_id_column(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnaubarrera/Desktop/MSc Computer Vision/TFM/labeled_plays_NBA/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Descargando vídeos:  65%|██████▍   | 323/500 [00:38<00:10, 17.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al descargar HoopCut_net/dataset/hoop_cut_373.mp4: Invalid URL 'False': No scheme supplied. Perhaps you meant https://False?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Descargando vídeos: 100%|██████████| 500/500 [00:58<00:00,  8.60it/s]\n"
     ]
    }
   ],
   "source": [
    "from download import download_videos_from_dataframe\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('HoopCut_net/labels_HoopCut.csv')\n",
    "\n",
    "download_videos_from_dataframe(df, 'HoopCut_net/dataset', max_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en 'PLAY TYPE': 16345\n",
      "Valores únicos en 'REBOUND TYPE': 1\n",
      "                             PLAY TYPE REBOUND TYPE\n",
      "0      Westbrook REBOUND (Off:1 Def:0)         OREB\n",
      "1      Westbrook REBOUND (Off:2 Def:0)             \n",
      "2      Westbrook REBOUND (Off:1 Def:1)             \n",
      "3      Westbrook REBOUND (Off:2 Def:1)             \n",
      "4      Westbrook REBOUND (Off:3 Def:2)             \n",
      "...                                ...          ...\n",
      "16340     Looney REBOUND (Off:3 Def:1)             \n",
      "16341     Looney REBOUND (Off:4 Def:1)             \n",
      "16342     Looney REBOUND (Off:2 Def:5)             \n",
      "16343     Looney REBOUND (Off:3 Def:5)             \n",
      "16344     Looney REBOUND (Off:4 Def:7)             \n",
      "\n",
      "[16345 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "oreb = 'output.csv'\n",
    "dreb = 'holy_grail/labels/DREB_all.csv'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def count_unique_values(csv_file):\n",
    "    # Leer el archivo CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Verificar si las columnas existen en el DataFrame\n",
    "    columns_to_check = [\"PLAY DESCRIPTION\", \"REBOUND TYPE\"]\n",
    "    missing_columns = [col for col in columns_to_check if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Las siguientes columnas no están en el archivo: {', '.join(missing_columns)}\")\n",
    "\n",
    "    # Obtener valores únicos\n",
    "    unique_play_type = df[\"PLAY DESCRIPTION\"].dropna().unique()\n",
    "    unique_rebound_type = df[\"REBOUND TYPE\"].dropna().unique()\n",
    "\n",
    "    # Contar valores únicos\n",
    "    play_type_count = len(unique_play_type)\n",
    "    rebound_type_count = len(unique_rebound_type)\n",
    "\n",
    "    # Crear un DataFrame con los valores distintos\n",
    "    unique_values_df = pd.DataFrame({\n",
    "        \"PLAY TYPE\": list(unique_play_type) + [\"\"] * (max(play_type_count, rebound_type_count) - play_type_count),\n",
    "        \"REBOUND TYPE\": list(unique_rebound_type) + [\"\"] * (max(play_type_count, rebound_type_count) - rebound_type_count)\n",
    "    })\n",
    "\n",
    "    return play_type_count, rebound_type_count, unique_values_df\n",
    "\n",
    "# Ejemplo de uso\n",
    "play_count, rebound_count, unique_df = count_unique_values(oreb)\n",
    "\n",
    "print(f\"Valores únicos en 'PLAY TYPE': {play_count}\")\n",
    "print(f\"Valores únicos en 'REBOUND TYPE': {rebound_count}\")\n",
    "print(unique_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        SEASON  PLAYER ID   PLAYER NAME REBOUND TYPE  \\\n",
      "60825  2018-19         42    Kyle Kuzma         OREB   \n",
      "60826  2018-19         42    Kyle Kuzma         OREB   \n",
      "60827  2018-19         42    Kyle Kuzma         OREB   \n",
      "60828  2018-19         42    Kyle Kuzma         OREB   \n",
      "60829  2018-19         42    Kyle Kuzma         OREB   \n",
      "...        ...        ...           ...          ...   \n",
      "65422  2018-19         95  Steven Adams         OREB   \n",
      "65423  2018-19         95  Steven Adams         OREB   \n",
      "65424  2018-19         95  Steven Adams         OREB   \n",
      "65425  2018-19         95  Steven Adams         OREB   \n",
      "65426  2018-19         95  Steven Adams         OREB   \n",
      "\n",
      "                  PLAY DESCRIPTION   BOXSCORE  VTM  HTM  \\\n",
      "60825  Kuzma REBOUND (Off:1 Def:1)  HOU @ LAL  HOU  LAL   \n",
      "60826  Kuzma REBOUND (Off:1 Def:0)  LAL @ PHX  LAL  PHX   \n",
      "60827  Kuzma REBOUND (Off:1 Def:1)  LAL @ SAS  LAL  SAS   \n",
      "60828  Kuzma REBOUND (Off:1 Def:3)  LAL @ MIN  LAL  MIN   \n",
      "60829  Kuzma REBOUND (Off:2 Def:3)  LAL @ MIN  LAL  MIN   \n",
      "...                            ...        ...  ...  ...   \n",
      "65422  Adams REBOUND (Off:6 Def:4)  HOU @ OKC  HOU  OKC   \n",
      "65423  Adams REBOUND (Off:7 Def:5)  HOU @ OKC  HOU  OKC   \n",
      "65424  Adams REBOUND (Off:8 Def:5)  HOU @ OKC  HOU  OKC   \n",
      "65425  Adams REBOUND (Off:1 Def:0)  OKC @ MIL  OKC  MIL   \n",
      "65426  Adams REBOUND (Off:2 Def:0)  OKC @ MIL  OKC  MIL   \n",
      "\n",
      "                   GAME DATE  PERIOD  \\\n",
      "60825   Saturday, October 20       4   \n",
      "60826  Wednesday, October 24       2   \n",
      "60827   Saturday, October 27       2   \n",
      "60828     Monday, October 29       4   \n",
      "60829     Monday, October 29       4   \n",
      "...                      ...     ...   \n",
      "65422       Tuesday, April 9       2   \n",
      "65423       Tuesday, April 9       3   \n",
      "65424       Tuesday, April 9       4   \n",
      "65425    Wednesday, April 10       3   \n",
      "65426    Wednesday, April 10       3   \n",
      "\n",
      "                                              Video Link  DOWNLOADED  \n",
      "60825  https://videos.nba.com/nba/pbp/media/2018/10/2...       False  \n",
      "60826  https://videos.nba.com/nba/pbp/media/2018/10/2...       False  \n",
      "60827  https://videos.nba.com/nba/pbp/media/2018/10/2...       False  \n",
      "60828  https://videos.nba.com/nba/pbp/media/2018/10/2...       False  \n",
      "60829  https://videos.nba.com/nba/pbp/media/2018/10/2...       False  \n",
      "...                                                  ...         ...  \n",
      "65422  https://videos.nba.com/nba/pbp/media/2019/04/0...       False  \n",
      "65423  https://videos.nba.com/nba/pbp/media/2019/04/0...       False  \n",
      "65424  https://videos.nba.com/nba/pbp/media/2019/04/0...       False  \n",
      "65425  https://videos.nba.com/nba/pbp/media/2019/04/0...       False  \n",
      "65426  https://videos.nba.com/nba/pbp/media/2019/04/0...       False  \n",
      "\n",
      "[4602 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def swap_columns_in_range(csv_file, start_row, end_row, output_file=\"output.csv\"):\n",
    "    # Leer el archivo CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Verificar si las columnas existen en el DataFrame\n",
    "    columns_to_swap = [\"PLAY DESCRIPTION\", \"REBOUND TYPE\"]\n",
    "    missing_columns = [col for col in columns_to_swap if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Las siguientes columnas no están en el archivo: {', '.join(missing_columns)}\")\n",
    "\n",
    "    # Asegurar que start_row y end_row están dentro del rango del DataFrame\n",
    "    if start_row < 0 or end_row >= len(df):\n",
    "        raise IndexError(\"El rango de filas está fuera de los límites del DataFrame.\")\n",
    "\n",
    "    # Intercambiar los valores de las dos columnas en el rango de filas\n",
    "    temp = df.loc[start_row:end_row, \"PLAY DESCRIPTION\"].copy()\n",
    "    df.loc[start_row:end_row, \"PLAY DESCRIPTION\"] = df.loc[start_row:end_row, \"REBOUND TYPE\"]\n",
    "    df.loc[start_row:end_row, \"REBOUND TYPE\"] = temp\n",
    "\n",
    "    # Guardar el archivo modificado\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Ejemplo de uso\n",
    "path_holy = \"HoopCut_net/\"\n",
    "csv_file = path_holy + \"OREB_all.csv\"\n",
    "start_row = 60825   # Fila donde comienza el intercambio\n",
    "end_row = 65426     # Fila donde termina el intercambio\n",
    "\n",
    "df_modificado = swap_columns_in_range(csv_file, start_row, end_row)\n",
    "print(df_modificado.loc[start_row:end_row])  # Mostrar las filas afectadas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Todos los videos tienen la tasa de FPS correcta.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def check_fps_in_folder(folder_path, target_fps=60):\n",
    "    \"\"\"\n",
    "    Revisa si todos los videos en una carpeta tienen la tasa de FPS esperada.\n",
    "\n",
    "    :param folder_path: Ruta de la carpeta que contiene los videos.\n",
    "    :param target_fps: FPS esperado (por defecto 60).\n",
    "    :return: Lista con videos que NO cumplen con los FPS y sus valores reales.\n",
    "    \"\"\"\n",
    "    non_matching_videos = []  # Almacena videos que no cumplen la condición\n",
    "    \n",
    "    # Obtener todos los archivos de la carpeta\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        # Verificar si es un archivo de video\n",
    "        if os.path.isfile(file_path) and file.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.flv')):\n",
    "            cap = cv2.VideoCapture(file_path)\n",
    "            if not cap.isOpened():\n",
    "                print(f\"⚠️ No se pudo abrir el archivo: {file}\")\n",
    "                continue\n",
    "            \n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)  # Obtener FPS del video\n",
    "            cap.release()\n",
    "            \n",
    "            if fps != target_fps:\n",
    "                non_matching_videos.append((file, fps))  # Guardar videos que no cumplen\n",
    "\n",
    "    # Mostrar resultados\n",
    "    if non_matching_videos:\n",
    "        print(\"❌ Algunos videos no cumplen con los FPS esperados:\")\n",
    "        for video, fps in non_matching_videos:\n",
    "            print(f\"  - {video}: {fps} FPS\")\n",
    "    else:\n",
    "        print(\"✅ Todos los videos tienen la tasa de FPS correcta.\")\n",
    "\n",
    "    return non_matching_videos  # Retorna la lista de videos fuera del estándar\n",
    "\n",
    "# 📌 Ejemplo de uso\n",
    "folder_path = \"HoopCut_net/dataset\"\n",
    "check_fps_in_folder(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
